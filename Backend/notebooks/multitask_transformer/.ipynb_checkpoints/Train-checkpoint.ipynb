{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'musicautobot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5a6515dabab7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmusicautobot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy_encode\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmusicautobot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_processing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprocess_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmusicautobot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmusicautobot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmusic_transformer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmusicautobot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultitask_transformer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'musicautobot'"
     ]
    }
   ],
   "source": [
    "from musicautobot.numpy_encode import *\n",
    "from musicautobot.utils.file_processing import process_all, process_file\n",
    "from musicautobot.config import *\n",
    "from musicautobot.music_transformer import *\n",
    "from musicautobot.multitask_transformer import *\n",
    "from musicautobot.utils.stacked_dataloader import StackedDataBunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultitaskTransformer Training\n",
    "\n",
    "Multitask Training is an extension of [MusicTransformer](../music_transformer/Train.ipynb).\n",
    "\n",
    "Instead a basic language model that predicts the next word...\n",
    "\n",
    "We train on multiple tasks\n",
    "* [Next Word](../music_transformer/Train.ipynb)\n",
    "* [Bert Mask](https://arxiv.org/abs/1810.04805)\n",
    "* [Sequence to Sequence Translation](http://jalammar.github.io/illustrated-transformer/)\n",
    "\n",
    "This gives a more generalized model and also let's you do some really cool [predictions](Generate.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End to end training pipeline \n",
    "\n",
    "1. Create and encode dataset\n",
    "2. Initialize Transformer MOdel\n",
    "3. Train\n",
    "4. Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of your midi files\n",
    "midi_path = Path('data/midi/examples')\n",
    "midi_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Location to save dataset\n",
    "data_path = Path('data/numpy')\n",
    "data_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "data_save_name = 'musicitem_data_save.pkl'\n",
    "s2s_data_save_name = 'multiitem_data_save.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Gather midi dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure all your midi data is in `musicautobot/data/midi` directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a pretty good dataset with lots of midi data:  \n",
    "https://www.reddit.com/r/datasets/comments/3akhxy/the_largest_midi_collection_on_the_internet/\n",
    "\n",
    "Download the folder and unzip it to `data/midi`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create dataset from MIDI files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_files = get_files(midi_path, '.mid', recurse=True); len(midi_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a. Create NextWord/Mask Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processors = [Midi2ItemProcessor()]\n",
    "data = MusicDataBunch.from_files(midi_files, data_path, processors=processors, \n",
    "                                 encode_position=True, dl_tfms=mask_lm_tfm_pitchdur, \n",
    "                                 bptt=5, bs=2)\n",
    "data.save(data_save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = data.one_batch(); xb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key:\n",
    "* 'msk' = masked input\n",
    "* 'lm' = next word input\n",
    "* 'pos' = timestepped postional encoding. This is in addition to relative positional encoding\n",
    "\n",
    "Note: MultitaskTransformer trains on both the masked input ('msk') and next word input ('lm') at the same time.\n",
    "\n",
    "The encoder is trained on the 'msk' data, while the decoder is trained on 'lm' data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Create sequence to sequence dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processors = [Midi2MultitrackProcessor()]\n",
    "s2s_data = MusicDataBunch.from_files(midi_files, data_path, processors=processors, \n",
    "                                     preloader_cls=S2SPreloader, list_cls=S2SItemList,\n",
    "                                     dl_tfms=melody_chord_tfm,\n",
    "                                     bptt=5, bs=2)\n",
    "s2s_data.save(s2s_data_save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = s2s_data.one_batch(); xb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key:\n",
    "* 'c2m' = chord2melody translation\n",
    " * enc = chord\n",
    " * dec = melody\n",
    "* 'm2c' = next word input\n",
    " * enc = melody\n",
    " * dec = chord\n",
    "* 'pos' = timestepped postional encoding. Gives the model a better reference when translating\n",
    "\n",
    "Note: MultitaskTransformer trains both translations ('m2c' and 'c2m') at the same time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "batch_size = 2\n",
    "bptt = 128\n",
    "\n",
    "lm_data = load_data(data_path, data_save_name, \n",
    "                    bs=batch_size, bptt=bptt, encode_position=True,\n",
    "                    dl_tfms=mask_lm_tfm_pitchdur)\n",
    "\n",
    "s2s_data = load_data(data_path, s2s_data_save_name, \n",
    "                     bs=batch_size//2, bptt=bptt,\n",
    "                     preloader_cls=S2SPreloader, dl_tfms=melody_chord_tfm)\n",
    "\n",
    "# Combine both dataloaders so we can train multiple tasks at the same time\n",
    "data = StackedDataBunch([lm_data, s2s_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model\n",
    "config = multitask_config(); config\n",
    "\n",
    "learn = multitask_model_learner(data, config.copy())\n",
    "# learn.to_fp16(dynamic=True) # Enable for mixed precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('example')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "\n",
    "---\n",
    "See [Generate.ipynb](Generate.ipynb) to use a pretrained model and generate better predictions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# midi_files = get_files(midi_path, '.mid', recurse=True)\n",
    "midi_file = Path('data/midi/notebook_examples/single_bar_example.mid'); midi_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_word = nw_predict_from_midi(learn, midi_file, n_words=20, seed_len=8); next_word.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_melody = s2s_predict_from_midi(learn, midi_file, n_words=20, seed_len=4, pred_melody=True); pred_melody.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_notes = mask_predict_from_midi(learn, midi_file, predict_notes=True); pred_notes.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
